# Parallel Pacman Simulator: High-Performance Multi-Agent Environment

Contributors: Po-Kai Huang, Henry Tsai, Shih-Wen Huang, Chih-Ying Liu, Max Lin

This project implements a high-performance, parallelized Pacman simulator using C (Kernel), OpenMP, and MPI, wrapped in Python. It demonstrates linear scaling (31.06x) on 32-core nodes and scales effectively to 144 distributed MPI ranks (~290k steps/s)

## üìã Compliance Matrix (For Graders)

We have met and exceeded all testing requirements. Here is a quick map to verify our submission:

| Requirement | Your Target | Our Count | Location in README |
| :--- | :--- | :--- | :--- |
| **Correctness Tests** | 25 Tests | **80+ Cases** | [See Correctness Tests](#correctness-tests) |
| **Speedup Tests** | 10 Tests | **10 Scenarios(Multiple Tests per Scenarios)** | [See Performance Tests](#performance-tests) |
| **Implementations** | 5 Variants | **5 Variants** | [See Implementations](#implementations) |




## üõ†Ô∏è Build & Installation

1.  **Prerequisites:**
    * OS: Linux / macOS
    * Compiler: GCC (with OpenMP support), MPI (OpenMPI / MPICH)
    * Python: 3.8+ (Required libraries: `numpy`, `pytest`, `mpi4py`, `matplotlib`)

2.  **Build the C Kernel:**
    The core simulation logic is written in C for maximum performance. You **must** compile it before running any Python script.

    ```bash
    cd csrc
    make clean && make
    cd ..
    ```
    *This generates `python/libpacman.so`, which is required for the Python wrapper.*

---
<a id="correctness-tests"></a>
## üß™ Correctness Tests 

We utilize `pytest` to run a comprehensive suite of unit and integration tests. The test suite covers game mechanics, thread safety, memory isolation, and MPI consistency.

**How to Run All Correctness Tests:**
```bash
cd python/tests
# Run the full suite with verbose output
pytest -v verify_00_mechanics.py level1/correctness/verify_01_thread_safety.py level2/correctness/verify_02_mem_isolation.py level3/correctness/verify_03_mpi_consistency.py
```
### Detailed Test Breakdown
**A. Game Mechanics & Scalability Stress (`verify_00_machanics.py`)**
- **Basic Integrity (5 Tests)**: Validates initialization, observation shapes, action bounds, reward structure, and reset mechanisms.
- **Physics Logic (2 Tests)**:Wall Collision: Verifies agents cannot walk through walls.Pacman Capture: Verifies game-over state and penalties when a ghost catches Pacman.
- **Scalability Stress Matrix (20 Tests)** :Uses `@pytest.mark.parametrize` to test 4 Grid Sizes (10x10 to 200x200) $\times$ 5 Agent Counts (1 to 4096). This ensures the C kernel handles extreme memory loads without segfaults.

**B. Level 1: Thread Safety (`level1/correctness/verify_01_thread_safety.py`)**
- **Thread Scaling Consistency (12 Tests)**: Compares simulation results across [2, 4, 8, 16] threads against a single-threaded baseline for 3 different step counts.
- **Agent Scaling (8 Tests)**: Verifies consistency for [16, 32, 64, 128] agents.
- **Edge Cases (6 Tests)**: Tests scenarios with "Half Dead" and "All Dead" ghosts to ensure logic holds when agents are inactive.
- **Deterministic Replay (4 Tests)**: Ensures different random seeds produce unique but reproducible results across thread counts.

**C. Level 2: Memory Isolation (`level2/correctness/verify_02_mem_isolation.py`)**
- **Environment Vectorization (20 Tests)**:Verifies that the parallel step_env_apply_actions_batch produces identical results to the sequential baseline across various n_envs (1 to 32) and thread counts.
- **Collision Isolation**: Ensures that walls and collisions in one environment do not bleed over into the memory space of another.

**D. Level 3: MPI Consistency (`level3/correctness/verify_03_mpi_consistemcy.py`)**
- **Consistency Check**: Verifies that running 16 environments on 1 MPI rank produces the exact same checksum as running them on 4 MPI ranks.
- **Load Balancing**: Tests correct handling of remainder environments (e.g., 10 envs on 3 ranks).
- **Oversubscription**: Verifies behavior when `rank_count > env_count`.
---
<a id="performance-tests"></a>
## üöÄ Performance & Speedup Tests 

We define 10 distinct performance scenarios to analyze speedup across different architectural levels. These are split into Experimental Analysis (`exp_`) and Full System Benchmarks (`run_g`).

### Part 1: Micro-Benchmarks & Scaling Analysis

Located in `python/tests/`

1.`exp_01_micro_scaling.sh:`
  - Goal: Analyzes Level 1 (Agent-parallelism) scaling.
  - Metric: Speedup vs. Agent Count (e.g., 128 to 512 in script, scalable to 4096).

2.`exp_02_throughput.sh:`
- Goal: Analyzes Level 2 (Environment-parallelism) strong scaling.

- Result: 31.06x speedup on 32 threads (Linear Scaling).

3.`exp_03_mpi_scaling.sh:`

- Goal: Analyzes Level 3 (MPI) distributed strong scaling (fixed total workload of 64 Envs) across nodes.

- Result: Scaled to 144 ranks with ~290k steps/s throughput.

4.`exp_04_hybrid_tradeoff.sh:`

- Goal: Compares Latency vs. Throughput between Hybrid and Pure MPI modes.

5.`exp_05_hybrid_multilevel.sh:`

- Goal: Evaluates hierarchical parallelism (MPI nodes + OpenMP threads).

`run_all_experiments.sh` to run every test in Micro-Benchmarks & Scaling Analysis

### Part 2: Full System Scenarios

Located in `python/`


6.`run_g1_singlenode.sh:`

- Goal: Baseline performance measurement on a single compute node.

7.`run_g2_cluster_baseline.sh:`

- Goal: Multi-node baseline without specific optimizations.
- Cautious: This test would take more time to run.

8.`run_g3_hybrid_opt.sh:`

- Goal: optimized Hybrid execution (e.g., 4 MPI Ranks x 8 OpenMP Threads).

9.`run_g4_pure_mpi.sh:`

- Goal: Pure MPI execution (1 process per core). (Best Distributed Performance).

10.`run_g5_edge_detection.sh:`

- Goal: Stress tests the system limits and Ghost Exchange overhead by pushing MPI ranks to the breakdown point (e.g., 160 ranks).

**How to Run a Performance Test:**
```bash
# Example: Run level 2 Speedup Test
cd python/tests
./exp_02_throughput.sh

# Example: Run Pure MPI Benchmark
cd python
./run_g4_pure_mpi.sh
```
---

## üìå Relation Between Report Tables and Scripts

The tables in the written report are **summary tables** aggregated from
multiple experimental runs under different configurations.
They are **not generated by a single script execution**.

To support reproducibility, we provide the following mapping from report
tables to the scripts used to generate their underlying results:

All scripts below are executed from the `python/` directory.
- **Table 1 (Single-node Architecture Comparison)**  
```bash
./run_g1_singlenode.sh
```
- **Table 2 (Distributed Strong Scaling)** 
```bash
./run_g2_cluster_baseline.sh 
./run_g4_pure_mpi.sh
```

- **Table 3 (Hybrid Process/Thread Trade-off)** 
```bash
./run_g2_cluster_baseline.sh
./run_g3_hybrid_opt.sh
```
- **Table 4 (Stress Testing & Stability Limits)** 
```bash
./run_g5_edge_detection.sh
```
**Note on Reproducibility.**
All reported tables summarize multiple experimental runs.
Exact numerical values may vary across executions due to system noise,
hardware differences, and cluster scheduling effects.
However, all reported performance trends and relative speedup
relationships are reproducible using the provided scripts.

---
<a id="implementations"></a>
## üß† 5 Parallel Implementations

To explore the trade-offs in parallel RL simulation, we implemented and compared 5 distinct variants:

1. **Sequential (Baseline)**: Single-threaded C kernel (`csrc/step_apply_sequential.c`). Used for correctness verification.

2. **Level 1 (Fine-Grained)**: OpenMP parallelism over Agents within a single environment (`python/tests/level1/speedup/worker_01_micro.py`). Best for few environments with complex agents.

3. **Level 2 (Coarse-Grained)**: OpenMP parallelism over Environments (`python/tests/level2/speedup/worker_02_throughput.py`). Best Thread-Scaling (31x speedup).

4. **Level 3 (Pure MPI)**: Distributed parallelism using MPI processes (`python/run_g4_pure_mpi.sh`). Best for scaling beyond one node.

5. **Hybrid (MPI + OpenMP)**: Hierarchical parallelism (`python/run_g3_hybrid_opt.sh`). Uses MPI across nodes and OpenMP within nodes.

---
## üìÇ Project Structure
```
.
‚îú‚îÄ‚îÄ csrc/               # C Source Code (Kernel)
‚îÇ   ‚îú‚îÄ‚îÄ common.h        # Shared data structures
‚îÇ   ‚îú‚îÄ‚îÄ step_*.c        # Core game logic
‚îÇ   ‚îî‚îÄ‚îÄ Makefile        # Build script
‚îú‚îÄ‚îÄ python/             # Python Wrapper & Logic
‚îÇ   ‚îú‚îÄ‚îÄ pacman_env.py   # ctypes interface class
‚îÇ   ‚îú‚îÄ‚îÄ run_g*.sh       # Full System Scenarios (G1-G5)
‚îÇ   ‚îî‚îÄ‚îÄ tests/          # Experiment scripts
‚îÇ       ‚îú‚îÄ‚îÄ exp_*.sh    # Analysis Experiments (01-05)
‚îÇ       ‚îú‚îÄ‚îÄ verify_*.py # Correctness Tests
‚îÇ       ‚îú‚îÄ‚îÄ level1/     # Thread parallelism
‚îÇ       ‚îú‚îÄ‚îÄ level2/     # Environment parallelism
‚îÇ       ‚îú‚îÄ‚îÄ level3/     # Distributed parallelism
‚îÇ       ‚îî‚îÄ‚îÄ results/    # Logs, plots from Microbenchmarks
‚îî‚îÄ‚îÄ results/            # Logs from Full System Scenarios
```


## üìä Results Summary

Full results and detailed analysis can be found in `final_performance_report.txt` and the formal Written Report.

### 1. Single-Node Performance (64 Cores)
We compared thread-based (OpenMP) vs. process-based (MPI) parallelism on a single node:

* **Pure MPI (Level 3):** **153,230 steps/s** (Recommended üèÜ)
* **OpenMP (Level 2):** 4,742 steps/s
* **Observation:** Pure MPI outperforms OpenMP by **>30x** in this Python-wrapped environment, demonstrating that process-based isolation is significantly more efficient for this specific workload.

### 2. Distributed Scaling (Cluster)
* **Peak Throughput:** Scaled effectively to **144 MPI Ranks**, reaching **~290,000 steps/s**.
* **Scalability:** The system demonstrates strong scaling across multiple nodes using the implemented "Ghost Exchange" communication pattern.

### 3. Conclusion
* **Recommendation:** **Pure MPI (Level 3)** is the primary recommended architecture for high-performance simulation.